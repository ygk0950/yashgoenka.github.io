{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba9f566-0f81-47ec-91b8-ed210b2f3885",
   "metadata": {},
   "source": [
    "# Project - Quiz Creation using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b508356f-3258-43a2-899f-0a9c15c8f03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248a8000-19d1-4d72-b4b9-3fc112d9533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/DELL/Downloads/Gen AI/Introduction to LangChain for Agentic AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb6ebceb-3dac-43c6-9b02-518bfaee2e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 3A49-4773\n",
      "\n",
      " Directory of C:\\Users\\DELL\\Downloads\\Gen AI\\Introduction to LangChain for Agentic AI\n",
      "\n",
      "14-06-2025  15:56    <DIR>          .\n",
      "10-06-2025  23:53    <DIR>          ..\n",
      "10-06-2025  23:53    <DIR>          Module 1\n",
      "10-06-2025  23:53    <DIR>          Module 2\n",
      "10-06-2025  23:53    <DIR>          Module 3\n",
      "10-06-2025  23:53    <DIR>          Module 4\n",
      "10-06-2025  23:53    <DIR>          Module 5\n",
      "10-06-2025  23:53    <DIR>          Module 6\n",
      "14-06-2025  15:56            72,092 Project-PromptEngg.pdf\n",
      "               1 File(s)         72,092 bytes\n",
      "               8 Dir(s)  124,627,169,280 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fb6bd-4815-4ff7-aa8f-0e58738f4bd1",
   "metadata": {},
   "source": [
    "### Loading the content from the PDF using PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c25d984-dc81-496f-8ec3-eb2e58d32a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Prompt Engineering? Prompt engineering is a practice within natural language processing (NLP) in artificial intelligence, where text is used to describe the task the AI should perform. Guided by this input, the AI generates an output, which could take various forms. The goal is to use human-understandable text to interact conversationally with models, allowing for flexibility in the model’ s performance due to the task description embedded in the prompt. What are Prompts? Prompts are detailed descriptions of the desired output from an AI model. They represent the interaction between the user and the model and help define what the AI is expected to do. The effectiveness of prompt engineering largely depends on how well the prompt is designed to guide the model. Examples of Prompt Engineering Prompts in large language models (LLMs) like ChatGPT or GPT -3 can range from simple text queries to complex instructions. The key to effective prompting is providing sufficient detail. Examples of prompts for various tasks include: Text Prompts (ChatGPT, GPT):\n",
      "● \"What’ s the difference between generative AI and traditional AI?\" ● \"Provide 10 variations for the headline, 'Top generative AI use cases for the enterprise.'\" ● \"Write an outline for an article on the benefits of generative AI for marketing.\" ● \"Generate 300 words for each section of an article on the benefits of generative AI.\" ● \"Craft a 100-word product description for ProductXYZ in five styles.\" ● \"Define types of prompt engineering basics in iambic pentameter , Shakespearean style.\" Code Prompts (ChatGPT, Codex): ● \"Act as an ASCII artist translating object names into ASCII code.\" ● \"Identify mistakes in the following code.\" ● \"Write a function to multiply two numbers and return the result.\" ● \"Develop a basic REST API in Python.\" ● \"Explain the function of this code snippet.\" ● \"Simplify the following code.\" Image Prompts (Stable Diffusion, Midjourney, DALL-E 2): ● \"Depict a dog in a car wearing sunglasses and a hat in the style of Salvador Dali.\" ● \"Illustrate a lizard on the beach in claymation art style.\"\n",
      "● \"Create an image of a man using a phone on the subway in 4K resolution with bokeh blur.\" ● \"Design a sticker illustration of a woman drinking coffee at a table with a checkered tablecloth.\" ● \"Visualize a jungle forest with cinematic lighting and nature photography .\" ● \"Generate a first-person view of looking out at orange clouds during sunrise.\" How to Engineer AI Prompts The quality of a prompt is critical. To improve prompt effectiveness, consider the following tips: ● Role Playing : Make the model act as a specific entity (e.g., teacher , code editor , interviewer) to tailor the interaction and target a specific outcome. ● Clarity : Remove ambiguity by being concise. Avoid unnecessary details that might confuse the model. ● Specification : Be specific in your instructions to direct the model’ s output clearly . ● Consistency : Maintain a consistent tone and flow in the prompt to ensure coherent and legible responses. Elements of a Prompt The components that make up a prompt include:\n",
      "● Instruction : A statement telling the model what task to perform. ● Context : Background information that helps the model understand the problem at hand. ● Input Data : The input data given to the model to process. ● Output Indicator : A specification of the expected output format (e.g., code, text, image). Standard Prompt Patterns Prompts generally follow specific formats: User-Model Interaction : User: <Instruction> Model: <Response> Few-Shot Prompting : Provides a few examples of the task to guide the model. <Instruction> <Response>\n",
      "<Instruction> <Response> <Instruction> <Response> Question-and-Answer Pattern : makefile Copy code Q: <Question>? A: <Answer> Q: <Question>? A: <Answer>\n",
      "● Prompting Techniques There are several advanced techniques for crafting effective prompts: 1. Zero-Shot Prompting : The model performs a task without having been specifically trained on it, relying on its general knowledge. Example: Prompt: \"Classify the text into neutral, negative, or positive.\" Text: \"I think the presentation was awesome.\" Sentiment: Positive 2. Few-Shot Prompting / In-Context Learning : The model is given a few examples to build upon, which helps it perform tasks more effectively . 3. Chain-of-Thought (CoT) : This technique allows the model to process complex reasoning by breaking down the task into intermediate steps, improving output quality . What to Avoid When Creating Prompts Avoid the following pitfalls when creating prompts: ● Information Overload : Too much detail can cause ambiguity and reduce the accuracy of responses.\n",
      "● Open-Ended Questions : Avoid vague or non-specific questions that may lead to imprecise responses. ● Poor Use of Constraints : Avoid giving the model too much freedom. Instead, specify boundaries or requirements to guide the output more effectively .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('Project-PromptEngg.pdf','rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    study_material = ''\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            study_material += text.replace('\\n', ' ') + '\\n'\n",
    "    print(study_material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed56427-04b2-4b07-8084-3d00b0d85943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(study_material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19eeec59-c2aa-48fa-9037-c2726e1700db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a757113-ba40-40ac-bdcc-318cc1cb3dcb",
   "metadata": {},
   "source": [
    "### Creating ChatGPT model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31490b40-09a4-4737-8b59-2bd4b1cc9b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI api key: ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "open_api_key = getpass('Enter your OpenAI api key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3956dde6-6656-4531-a55f-4298e0ba0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05a16253-a116-48f3-9728-39a5474a775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cf8e916b-03f3-41eb-a9ed-99cc2a3d0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4ab0b-6039-431e-af86-e569e4ae0e9a",
   "metadata": {},
   "source": [
    "### Creating the Input Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d30cda94-5f0f-4e83-b248-3b3d7f8fc196",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_txt = '''\n",
    "You are an expert in summarizing educational material and designing quiz questions for student assessment.\n",
    "\n",
    "Begin by writing a section titled **Summary**, where you convert the given study material into 3–5 clear and concise bullet points. Avoid using terms like \"Definition\", \"Prompt\" within the points themselves. Focus on the core concepts and avoid redundancy.\n",
    "\n",
    "After that, write a second section titled **Quiz Questions**.\n",
    "\n",
    "Here you generate multiple choice questions to test understanding of the material. Leave a line\n",
    "\n",
    "Follow these rules:\n",
    "- Each question should have 4 options: a), b), c), and d)\n",
    "- The correct answer should be randomly placed among the options\n",
    "- Format the answer as: **Answer: <letter>)**\n",
    "- Do not include any section headers like \"Task 1\" or \"Task 2\" in your response\n",
    "\n",
    "Use this format for questions:\n",
    "\n",
    "What is the main purpose of prompt engineering?\n",
    "a) Option 1  \n",
    "b) Option 2  \n",
    "c) Option 3  \n",
    "d) Option 4  \n",
    "**Answer: b)**\n",
    "\n",
    "Now use the following study material:\n",
    "\n",
    "{input_study_material}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "bebb4bad-0541-4cfb-a975-3cc889474e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt,\n",
    "    input_variables=[\"input_study_material\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4468e5c-08ee-4306-98d9-12ead8602672",
   "metadata": {},
   "source": [
    "### Building the LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0bdf11b3-7bef-4aab-9c59-f6a5262531a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    prompt\n",
    "    |\n",
    "    chatgpt\n",
    "    |\n",
    "    StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45288e7-6b68-4abb-a43e-54d0964f3406",
   "metadata": {},
   "source": [
    "### Invoking the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6f35f5cd-db48-4104-946c-7fd002f2918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({\"input_study_material\": study_material})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "628e4ec6-61e8-44bb-b284-260fc9ab569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary**  \n",
      "- Prompt engineering is a practice in natural language processing that uses text to instruct AI on tasks, enabling flexible interactions.  \n",
      "- Prompts serve as detailed descriptions of desired outputs, influencing the AI's performance based on their design.  \n",
      "- Effective prompts can vary in complexity and format, including text, code, and image prompts, with clarity and specificity being crucial for success.  \n",
      "- Key components of a prompt include instruction, context, input data, and output indicators, while common patterns include user-model interaction and few-shot prompting.  \n",
      "- Advanced prompting techniques like zero-shot, few-shot, and chain-of-thought enhance the model's ability to perform tasks effectively, while avoiding pitfalls such as information overload and vague questions is essential.  \n",
      "\n",
      "**Quiz Questions**  \n",
      "\n",
      "What is the primary function of prompt engineering in AI?  \n",
      "a) To create visual art  \n",
      "b) To describe tasks for AI to perform  \n",
      "c) To analyze data sets  \n",
      "d) To develop software applications  \n",
      "**Answer: b)**  \n",
      "\n",
      "Which of the following is NOT a component of a prompt?  \n",
      "a) Instruction  \n",
      "b) Context  \n",
      "c) Output Indicator  \n",
      "d) User Feedback  \n",
      "**Answer: d)**  \n",
      "\n",
      "What is an example of a few-shot prompting technique?  \n",
      "a) Providing no examples for the model  \n",
      "b) Giving multiple examples to guide the model  \n",
      "c) Asking a single question  \n",
      "d) Using vague instructions  \n",
      "**Answer: b)**  \n",
      "\n",
      "What should be avoided when creating prompts?  \n",
      "a) Clear and concise instructions  \n",
      "b) Specific output indicators  \n",
      "c) Information overload  \n",
      "d) Contextual background information  \n",
      "**Answer: c)**  \n",
      "\n",
      "Which technique allows a model to reason through complex tasks by breaking them into steps?  \n",
      "a) Zero-Shot Prompting  \n",
      "b) Few-Shot Prompting  \n",
      "c) Chain-of-Thought  \n",
      "d) User-Model Interaction  \n",
      "**Answer: c)**  \n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e280f957-2e12-46ab-b6d7-9194be2e6873",
   "metadata": {},
   "source": [
    "### Displaying the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "50f78adf-72ff-4bed-b1e0-d45aa05ff9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4122d07c-f138-4de6-bddf-1b46d9961357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**  \n",
       "- Prompt engineering is a practice in natural language processing that uses text to instruct AI on tasks, enabling flexible interactions.  \n",
       "- Prompts serve as detailed descriptions of desired outputs, influencing the AI's performance based on their design.  \n",
       "- Effective prompts can vary in complexity and format, including text, code, and image prompts, with clarity and specificity being crucial for success.  \n",
       "- Key components of a prompt include instruction, context, input data, and output indicators, while common patterns include user-model interaction and few-shot prompting.  \n",
       "- Advanced prompting techniques like zero-shot, few-shot, and chain-of-thought enhance the model's ability to perform tasks effectively, while avoiding pitfalls such as information overload and vague questions is essential.  \n",
       "\n",
       "**Quiz Questions**  \n",
       "\n",
       "What is the primary function of prompt engineering in AI?  \n",
       "a) To create visual art  \n",
       "b) To describe tasks for AI to perform  \n",
       "c) To analyze data sets  \n",
       "d) To develop software applications  \n",
       "**Answer: b)**  \n",
       "\n",
       "Which of the following is NOT a component of a prompt?  \n",
       "a) Instruction  \n",
       "b) Context  \n",
       "c) Output Indicator  \n",
       "d) User Feedback  \n",
       "**Answer: d)**  \n",
       "\n",
       "What is an example of a few-shot prompting technique?  \n",
       "a) Providing no examples for the model  \n",
       "b) Giving multiple examples to guide the model  \n",
       "c) Asking a single question  \n",
       "d) Using vague instructions  \n",
       "**Answer: b)**  \n",
       "\n",
       "What should be avoided when creating prompts?  \n",
       "a) Clear and concise instructions  \n",
       "b) Specific output indicators  \n",
       "c) Information overload  \n",
       "d) Contextual background information  \n",
       "**Answer: c)**  \n",
       "\n",
       "Which technique allows a model to reason through complex tasks by breaking them into steps?  \n",
       "a) Zero-Shot Prompting  \n",
       "b) Few-Shot Prompting  \n",
       "c) Chain-of-Thought  \n",
       "d) User-Model Interaction  \n",
       "**Answer: c)**  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e2f93-7f00-4c6b-88ce-280f1e4738e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual GPU Env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
